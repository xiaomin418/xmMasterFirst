#### 1. Requiremnt:
如./requirements.txt文件所示。

#### 2.How to run?

（a）运行python feedforward.py --batch_size 6 --input_size 3 --hidden_size 6 --output_size 3 --lr 0.001 --iter 10000

![运行示例2](D:\document\研一课程\pythonProject\feedforward\运行示例2.jpg)

参数说明：

--batch_size：批处理个数，batch_size=1为单样本方式更新权重；

--input_size：输入数据维度（=3）；

--hidden_size：隐层神经元个数；

 --output_size：输出数据维度，数据有三类，因此输出数据用onehot表示，维度为3；

 --lr：梯度更新步长，即学习率；

--iter：迭代轮次；

（b）测试结果以命令行打印输出

![运行示例1](D:\document\研一课程\pythonProject\feedforward\运行示例1.jpg)



#### 3.源文件说明

'./data.txt'：训练数据样本

'./test.txt'：测试数据样本

'./lr0.1', './lr0.01', './lr0.001'：在设置不同学习率下，隐层神经元个数对精度和平均损失影响，数据格式如下：

```
#lr0.1
#隐层神经元个数 精度 平均损失
1 0.34465910036903535 0.5
2 0.30272214961618055 0.8333333333333334
3 0.2747768139219829 0.6666666666666666
4 0.48043526118521696 0.3333333333333333
5 0.36479736825020104 0.5
6 0.33477969028553095 0.5
7 0.5172805453938195 0.5
8 0.46782217095057493 0.5
10 0.30998088449293365 0.6666666666666666
12 0.3608700149696911 0.5
14 0.4097251105843926 0.6666666666666666
16 0.3655857999661684 0.5
20 0.2858335345457324 0.6666666666666666
24 0.3895344656359419 0.5
```

'./loss_batch_size_1.txt', './loss_batch_size_4.txt', './loss_batch_size_6.txt', './loss_batch_size_8.txt'：在设置不同batch_size下，目标函数随着迭代次数增加的变化；